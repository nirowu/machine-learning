{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "934b83ed",
      "metadata": {
        "id": "934b83ed"
      },
      "source": [
        "# Dataset2: sentiment-analysis-on-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "ab7c0d5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7c0d5d",
        "outputId": "b6540bf9-c22f-4305-f1c2-2888c549916a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import pad_sequences\n",
        "from collections import Counter\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore', category=UserWarning, module='bs4')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "102f456d",
      "metadata": {
        "id": "102f456d"
      },
      "outputs": [],
      "source": [
        "def read_file(path):\n",
        "  rawdata = pd.read_excel(path)\n",
        "  return rawdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "351d037d",
      "metadata": {
        "id": "351d037d"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "  reviews = []\n",
        "  for raw in tqdm(df['Phrase']):\n",
        "      text = BeautifulSoup(raw, 'lxml').get_text()\n",
        "      only_text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "      words = word_tokenize(only_text.lower())\n",
        "      stops = set(stopwords.words('english'))\n",
        "      non_stopwords = [word for word in words if not word in stops]\n",
        "      lemma_words = [lemmatizer.lemmatize(word) for word in non_stopwords]    \n",
        "      reviews.append(lemma_words)\n",
        "  return reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "6fb102e7",
      "metadata": {
        "id": "6fb102e7"
      },
      "outputs": [],
      "source": [
        "def tokenizer_preprocess(list_X_train, list_X_val):\n",
        "    unique_words = set()\n",
        "    len_max = 0\n",
        "    for sent in tqdm(list_X_train):\n",
        "        unique_words.update(sent)\n",
        "        if len_max < len(sent):\n",
        "            len_max = len(sent)\n",
        "    len(list(unique_words)), len_max\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "    tokenizer.fit_on_texts(list(list_X_train))\n",
        "     \n",
        "    X_train = tokenizer.texts_to_sequences(list_X_train)\n",
        "    X_train = pad_sequences(X_train, maxlen=len_max)\n",
        "\n",
        "    X_val = tokenizer.texts_to_sequences(list_X_val)\n",
        "    X_val = pad_sequences(X_val, maxlen=len_max)\n",
        "\n",
        "    return X_train, X_val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for standardizing data\n",
        "def standardScaler(feature_array):\n",
        "    num = feature_array.shape[1] # total number of columns\n",
        "    for i in range(num): # iterating through each column\n",
        "        feature = feature_array[:, i]\n",
        "        mean = feature.mean() # mean stores mean value for the column\n",
        "        std = feature.std() # std stores standard deviation value for the column\n",
        "        feature_array[:, i] = (feature_array[:, i] - mean) / std # standard scaling of each element of the column\n",
        "    return feature_array\n"
      ],
      "metadata": {
        "id": "j_hyT3IkOMZB"
      },
      "id": "j_hyT3IkOMZB",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "2eca902a",
      "metadata": {
        "id": "2eca902a"
      },
      "outputs": [],
      "source": [
        "def report(predictions, y_test):\n",
        "    print('Accuracy: %s' % accuracy_score(y_test, predictions))\n",
        "    print('Confusion Matrix:')\n",
        "    print(confusion_matrix(y_test, predictions))\n",
        "    print('Classification Report:')\n",
        "    print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n"
      ],
      "metadata": {
        "id": "zfN0fVV3-ZiS"
      },
      "id": "zfN0fVV3-ZiS"
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(x):\n",
        "    '''\n",
        "    calculates entropy of x\n",
        "    \n",
        "    input_ : x (a list of values)\n",
        "    output : float, entropy value\n",
        "    '''\n",
        "    counts = np.bincount(np.array(x, dtype=np.int64))\n",
        "    percentages = counts / len(x)\n",
        "\n",
        "    # Caclulate entropy\n",
        "\n",
        "    entropy = 0\n",
        "    for p in percentages:\n",
        "        if p > 0:\n",
        "            entropy += p * np.log2(p)\n",
        "    entropy = -entropy\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "zHfG4McRGPb2"
      },
      "execution_count": 110,
      "outputs": [],
      "id": "zHfG4McRGPb2"
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(parent, left_child, right_child):\n",
        "    '''\n",
        "    calculates information gain of a node  \n",
        "    \n",
        "    input_ : parent_list, child_list (left child and right child)\n",
        "    output : float, information gain value\n",
        "    '''\n",
        "    left_num = len(left_child) / len(parent)\n",
        "    right_num = len(right_child) / len(parent)\n",
        "\n",
        "    child = left_num * entropy(left_child) + right_num * entropy(right_child)\n",
        "    \n",
        "    return entropy(parent) - child"
      ],
      "metadata": {
        "id": "R2V-336dGgZT"
      },
      "execution_count": 111,
      "outputs": [],
      "id": "R2V-336dGgZT"
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    '''\n",
        "    define the node in the decistion tree\n",
        "    \n",
        "    '''\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "zR4lAYEcllot"
      },
      "id": "zR4lAYEcllot",
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "  '''\n",
        "  implementing decisicion tree  \n",
        "  \n",
        "  '''\n",
        "  def __init__(self, min_samples_split=2, max_depth=3):\n",
        "      self.min_samples_split = min_samples_split\n",
        "      self.max_depth = max_depth\n",
        "      self.root = None\n",
        "      \n",
        "  def _best_split(self, X, y):\n",
        "      '''\n",
        "      calculates the best split for given features and target  \n",
        "      \n",
        "      input_ : X = features, y = target \n",
        "      output : best_split (dict)\n",
        "      '''\n",
        "      best_split = {}\n",
        "      best_info_gain = -1\n",
        "      n_rows, n_cols = X.shape\n",
        "      \n",
        "      # For every dataset feature\n",
        "      for f_idx in range(n_cols):\n",
        "          X_curr = X[:, f_idx]\n",
        "          # For every unique value of that feature\n",
        "          for threshold in np.unique(X_curr):\n",
        "              # Construct a dataset and split it to the left and right parts\n",
        "              # Left part includes records lower or equal to the threshold\n",
        "              # Right part includes records higher than the threshold\n",
        "              df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "              df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "              df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "              # Do the calculation only if there's data in both subsets\n",
        "              if len(df_left) > 0 and len(df_right) > 0:\n",
        "                  # Obtain the value of the target variable for subsets\n",
        "                  y = df[:, -1]\n",
        "                  y_left = df_left[:, -1]\n",
        "                  y_right = df_right[:, -1]\n",
        "\n",
        "                  # Caclulate the information gain and save the split parameters\n",
        "                  # if the current split if better then the previous best\n",
        "                  gain = information_gain(y, y_left, y_right)\n",
        "                  if gain > best_info_gain:\n",
        "                      best_split = {\n",
        "                          'feature_index': f_idx,\n",
        "                          'threshold': threshold,\n",
        "                          'df_left': df_left,\n",
        "                          'df_right': df_right,\n",
        "                          'gain': gain\n",
        "                      }\n",
        "                      best_info_gain = gain\n",
        "      return best_split\n",
        "  \n",
        "  def _build(self, X, y, depth=0):\n",
        "      '''\n",
        "      build a decision tree   \n",
        "      \n",
        "      input_ : X = features, y = target, depth \n",
        "      output : node\n",
        "      '''\n",
        "      n_rows, n_cols = X.shape\n",
        "      \n",
        "      # Check to see if a node should be leaf node\n",
        "      if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "          # Get the best split\n",
        "          best = self._best_split(X, y)\n",
        "          # If the split isn't pure\n",
        "          if best['gain'] > 0:\n",
        "              # Build a tree on the left\n",
        "              left = self._build(\n",
        "                  X=best['df_left'][:, :-1], \n",
        "                  y=best['df_left'][:, -1], \n",
        "                  depth=depth + 1\n",
        "              )\n",
        "              right = self._build(\n",
        "                  X=best['df_right'][:, :-1], \n",
        "                  y=best['df_right'][:, -1], \n",
        "                  depth=depth + 1\n",
        "              )\n",
        "              return Node(\n",
        "                  feature=best['feature_index'], \n",
        "                  threshold=best['threshold'], \n",
        "                  data_left=left, \n",
        "                  data_right=right, \n",
        "                  gain=best['gain']\n",
        "              )\n",
        "      # Leaf node - value is the most common target value \n",
        "      return Node(\n",
        "          value=Counter(y).most_common(1)[0][0]\n",
        "      )\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "      '''\n",
        "      Train with given features and target  \n",
        "      \n",
        "      input_ : X = features, y = target \n",
        "      output : //\n",
        "      '''\n",
        "      # Call a recursive function to build the tree\n",
        "      self.root = self._build(X, y)\n",
        "      \n",
        "  def _predict(self, x, tree):\n",
        "      '''\n",
        "      classify a single test data  \n",
        "      \n",
        "      input_ : x (one input data)\n",
        "      output : class (prediction)\n",
        "      '''\n",
        "      # Leaf node\n",
        "      if tree.value != None:\n",
        "          return tree.value\n",
        "      feature_value = x[tree.feature]\n",
        "      \n",
        "      # Go to the left\n",
        "      if feature_value <= tree.threshold:\n",
        "          return self._predict(x=x, tree=tree.data_left)\n",
        "      \n",
        "      # Go to the right\n",
        "      if feature_value > tree.threshold:\n",
        "          return self._predict(x=x, tree=tree.data_right)\n",
        "      \n",
        "  def predict(self, X):\n",
        "      '''\n",
        "      classify all data\n",
        "      \n",
        "      :param X: np.array, features\n",
        "      :return: np.array, predicted classes\n",
        "      '''\n",
        "      # Call the _predict() function for every observation\n",
        "      return [self._predict(x, self.root) for x in X]"
      ],
      "metadata": {
        "id": "Q7CcJJt3lq56"
      },
      "id": "Q7CcJJt3lq56",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect google drive and Import training data and testing data\n"
      ],
      "metadata": {
        "id": "5seXO3GNz80T"
      },
      "id": "5seXO3GNz80T"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NhzzI1mT2j5",
        "outputId": "8cc4053b-5bc5-4c81-9fc5-af0b9fe5e281"
      },
      "id": "9NhzzI1mT2j5",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "30dbc21c",
      "metadata": {
        "id": "30dbc21c"
      },
      "outputs": [],
      "source": [
        "# read_file(path): trianing_data features, trianing_data target, testing_data features \n",
        "train_x = read_file('/content/drive/MyDrive/ml_hw/Dataset2_train/Dataset2_train/X_train.xlsx')\n",
        "train_y = read_file('/content/drive/MyDrive/ml_hw/Dataset2_train/Dataset2_train/y_train.xlsx')\n",
        "test_x = read_file('/content/drive/MyDrive/ml_hw/Dataset2_test/X_test.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dealing missing data"
      ],
      "metadata": {
        "id": "Q45q5TEw_ABK"
      },
      "id": "Q45q5TEw_ABK"
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in train_x:\n",
        "  train_x[feature] = train_x[feature].fillna((train_x[feature][0]))"
      ],
      "metadata": {
        "id": "rQE8OjiNTH4A"
      },
      "id": "rQE8OjiNTH4A",
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turn the input data to suitable datatye"
      ],
      "metadata": {
        "id": "fktbPTvP_SUw"
      },
      "id": "fktbPTvP_SUw"
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "31b5c00c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31b5c00c",
        "outputId": "b7501fb1-16cc-4946-deb1-c7c0eddccf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 12544/124848 [00:07<01:04, 1731.10it/s]/usr/local/lib/python3.8/dist-packages/bs4/__init__.py:270: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  warnings.warn(\n",
            "100%|██████████| 124848/124848 [01:14<00:00, 1683.55it/s]\n",
            " 24%|██▍       | 7594/31212 [00:04<00:13, 1688.92it/s]/usr/local/lib/python3.8/dist-packages/bs4/__init__.py:270: UserWarning: \"b'drive'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  warnings.warn(\n",
            "100%|██████████| 31212/31212 [00:18<00:00, 1643.18it/s]\n"
          ]
        }
      ],
      "source": [
        "train_text = preprocess_data(train_x)\n",
        "test_text = preprocess_data(test_x)\n",
        "# target = train_y.Sentiment.values\n",
        "# X_train, X_val, y_train, y_val = train_test_split(train_text, target, test_size=0.2, stratify=target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "2f12ac0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f12ac0e",
        "outputId": "04c0f1f5-f53b-41c0-8090-53cb3edfd046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 124848/124848 [00:00<00:00, 862460.19it/s]\n"
          ]
        }
      ],
      "source": [
        "X_train_, X_test_ = tokenizer_preprocess(train_text, test_text)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "5345dd5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5345dd5a",
        "outputId": "998bd27f-dc7a-4817-c88f-8d34385c8245"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((124848, 30), (124848, 1), (31212, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "features = np.array(X_train_)\n",
        "target = np.array(train_y.to_numpy())\n",
        "features_test = np.array(X_test_)\n",
        "features.shape, target.shape, features_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_scaled = standardScaler(X_train_) \n",
        "testfeat_scaled = standardScaler(X_test_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QKzualiTBef",
        "outputId": "4042309c-d982-4754-c501-587e7394719c"
      },
      "id": "4QKzualiTBef",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-108-5aa0414773a2>:8: RuntimeWarning: invalid value encountered in true_divide\n",
            "  feature_array[:, i] = (feature_array[:, i] - mean) / std # standard scaling of each element of the column\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(features_scaled)\n",
        "y_train = np.array(train_y['Sentiment'].to_numpy())\n",
        "X_test = np.array(testfeat_scaled)\n",
        "X_train.shape, y_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg3FJ-91RmEh",
        "outputId": "b3e8e285-ce8b-431c-b2ba-3dbc14ec8ec1"
      },
      "id": "Mg3FJ-91RmEh",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((124848, 30), (124848,), (31212, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Observation\n",
        "\n"
      ],
      "metadata": {
        "id": "nWhRvUHN-5cY"
      },
      "id": "nWhRvUHN-5cY"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96a150d",
        "outputId": "2c962673-a578-4ac8-db5f-75f2874ebac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                           going to a house party and\n",
            "1                                      a grand picture\n",
            "2                                  lightweight meaning\n",
            "3                                      most unpleasant\n",
            "4    You can see the would-be surprises coming a mi...\n",
            "5    this too-extreme-for-TV rendition of the notor...\n",
            "6                    wickedly undramatic central theme\n",
            "7    ... a fascinating curiosity piece -- fascinati...\n",
            "8              fallible human beings , not caricatures\n",
            "9    is so prolonged and boring it is n't even clos...\n",
            "Name: Phrase, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_x['Phrase'].head(10))"
      ],
      "id": "b96a150d"
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bffd70e",
        "outputId": "8f98ec91-4605-43e7-fa2a-4f6842a812a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    124848.000000\n",
            "mean          2.063581\n",
            "std           0.893844\n",
            "min           0.000000\n",
            "25%           2.000000\n",
            "50%           2.000000\n",
            "75%           3.000000\n",
            "max           4.000000\n",
            "Name: Sentiment, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(train_y['Sentiment'].describe())"
      ],
      "id": "5bffd70e"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3b3202c",
        "outputId": "980057c0-6d2e-4714-bca3-4ec34cb7f986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    63665\n",
            "3    26342\n",
            "1    21818\n",
            "4     7365\n",
            "0     5658\n",
            "Name: Sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_y['Sentiment'].value_counts())"
      ],
      "id": "c3b3202c"
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66ca844",
        "outputId": "94eef218-43d0-4554-8b88-161ef0189e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    0.509940\n",
            "3    0.210993\n",
            "1    0.174757\n",
            "4    0.058992\n",
            "0    0.045319\n",
            "Name: Sentiment, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(train_y['Sentiment'].value_counts()/train_y['Sentiment'].count())"
      ],
      "id": "f66ca844"
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = train_x.isnull().sum().reset_index()\n",
        "temp_df['Percentage of Null Values'] = temp_df[0]/len(train_x)*100\n",
        "temp_df.columns = ['Column Name', 'Number of Null Values','Percentage of Null Values']\n",
        "temp_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "tEriY-OYe3MG",
        "outputId": "77441067-ff4d-4313-f98e-cab48d5a4c8d"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Column Name  Number of Null Values  Percentage of Null Values\n",
              "0      Phrase                      0                        0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3f944ba-f785-4d96-a608-1e0d0915e692\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column Name</th>\n",
              "      <th>Number of Null Values</th>\n",
              "      <th>Percentage of Null Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3f944ba-f785-4d96-a608-1e0d0915e692')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3f944ba-f785-4d96-a608-1e0d0915e692 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3f944ba-f785-4d96-a608-1e0d0915e692');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "id": "tEriY-OYe3MG"
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.describe().T.style.background_gradient(cmap = \"magma\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "cze-f2zGfXHG",
        "outputId": "125c9138-49f0-47c0-d2be-46bee3a11c91"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7ff0ef4c24c0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_79321_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >count</th>\n",
              "      <th class=\"col_heading level0 col1\" >unique</th>\n",
              "      <th class=\"col_heading level0 col2\" >top</th>\n",
              "      <th class=\"col_heading level0 col3\" >freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_79321_level0_row0\" class=\"row_heading level0 row0\" >Phrase</th>\n",
              "      <td id=\"T_79321_row0_col0\" class=\"data row0 col0\" >124848</td>\n",
              "      <td id=\"T_79321_row0_col1\" class=\"data row0 col1\" >124847</td>\n",
              "      <td id=\"T_79321_row0_col2\" class=\"data row0 col2\" >going to a house party and</td>\n",
              "      <td id=\"T_79321_row0_col3\" class=\"data row0 col3\" >2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "id": "cze-f2zGfXHG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with decision tree"
      ],
      "metadata": {
        "id": "8aZ7kf77_O00"
      },
      "id": "8aZ7kf77_O00"
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "547d1307",
      "metadata": {
        "id": "547d1307"
      },
      "outputs": [],
      "source": [
        "model = DecisionTree()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output data and Save the reult in excel file"
      ],
      "metadata": {
        "id": "fZ6fpUZ6_QC2"
      },
      "id": "fZ6fpUZ6_QC2"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.array(preds))\n",
        "df.to_excel(\"Dataset2_pred.xlsx\")"
      ],
      "metadata": {
        "id": "XIZLtJaA_wtv"
      },
      "id": "XIZLtJaA_wtv",
      "execution_count": 129,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q45q5TEw_ABK"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}